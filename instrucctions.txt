Instrucciones mÃ­as:
Quiero que siempre tengas en la mente que quiero realizar el proyecto aquÃ­ en local de visualstudiocode en una jupyter notebook pero que debes de tener en mente que todo lo que hagamos deberÃ¡ de ser compatible con Google Colab, por ejemplo el importar la base de datos al notebook, no es posible que la tengamos en el mismo entorno porque no subirÃ© los archivos en conjunto solamente el ipynb.
AdemÃ¡s tienes que trabajar con la estructura que ya se nos plantea en el @TelecomX_LATAM.ipynb. Tienes que analizar las siguientes instrucciones generales, despÃºes ir haciendo secciÃ³n por secciÃ³n de lo que solicitan.
Otro punto importante es que necesito tener un control de versiones en GitHub, para lo cual planeo que hagamos avances de un punto x a un punto y para subirlo y despÃºes avanzar de nuevo con el mismo mÃ©todo.
Cuando detectes algo escrito entre "& aqui &" significa que es mi comentario en medio de las instrucciones, asÃ­ indicarÃ© que ya hice o notas necesarias que surgan mientras trabajamos.
Instrucciones del proyecto desde aquÃ­:
/

IntroducciÃ³n al DesafÃ­o Telecom X

El desafÃ­o Telecom X ofrece una oportunidad Ãºnica para aplicar habilidades esenciales de anÃ¡lisis de datos en un escenario de negocios real.

AplicaciÃ³n prÃ¡ctica del conocimiento
La limpieza y tratamiento de datos es una habilidad fundamental para cualquier analista de datos. La manipulaciÃ³n de grandes volÃºmenes de informaciÃ³n exige la capacidad de identificar y corregir inconsistencias en los datos, como valores nulos, duplicados y datos fuera de estÃ¡ndar. Garantizar que los datos estÃ©n listos para el anÃ¡lisis es un paso esencial para obtener resultados precisos y confiables.

El anÃ¡lisis exploratorio de datos (EDA) es una etapa crucial para comprender en profundidad los datos. La capacidad de aplicar estadÃ­sticas descriptivas y generar visualizaciones permite identificar patrones, tendencias y relaciones entre las variables. Esto ayuda a formular hipÃ³tesis y generar insights que pueden influir en decisiones estratÃ©gicas dentro de la empresa.

Al participar en este desafÃ­o, aplicarÃ¡s conocimientos esenciales para el anÃ¡lisis de grandes volÃºmenes de datos en un contexto real, donde tus hallazgos podrÃ¡n impactar directamente en las estrategias de la empresa para mejorar el principal problema que estÃ¡n enfrentando.

Este desafÃ­o no solo contribuye a tu crecimiento en el Ã¡rea de Data Science, sino que tambiÃ©n ofrece la oportunidad de entender cÃ³mo la ciencia de datos puede aplicarse para resolver problemas reales que enfrentan las empresas en el mercado.

/

Enfoque en el Proceso de ETL
El principal objetivo de este desafÃ­o es desarrollar tus habilidades en ETL (Extract, Transform, Load) con Python. Los datos para este desafÃ­o estÃ¡n disponibles en una API.

Accede a los datos de la API
TelecomX Datos
En este desafÃ­o, el enfoque estÃ¡ en el proceso de extracciÃ³n de datos desde la API, limpieza y transformaciÃ³n. DespuÃ©s de esta etapa de procesamiento, deberÃ¡s organizar los datos de manera que permitan anÃ¡lisis mÃ¡s profundos y visualizaciones.

Como apoyo adicional, hemos creado un cuaderno base opcional para ayudarte a estructurar mejor el desafÃ­o. Este cuaderno proporciona una base inicial, sugiriendo un flujo de trabajo organizado y buenas prÃ¡cticas para el proceso de ETL. Puedes usarlo como guÃ­a durante la ejecuciÃ³n del desafÃ­o, pero tambiÃ©n tienes la opciÃ³n de no utilizarlo y estructurar la soluciÃ³n por tu cuenta.

Accede al cuaderno base (opcional)
Cuaderno Base - Telecom X
Al completar este desafÃ­o, habrÃ¡s aplicado competencias esenciales en ETL, fundamentales para el trabajo de un analista de datos y otras Ã¡reas dentro de Data Science.

/

Indicaciones

/

ğŸ’¡Acerca del desafÃ­o ğŸ’¡
DescripciÃ³n
Telecom X - AnÃ¡lisis de EvasiÃ³n de Clientes
Has sido contratado como asistente de anÃ¡lisis de datos en Telecom X y formarÃ¡s parte del proyecto "Churn de Clientes". La empresa enfrenta una alta tasa de cancelaciones y necesita comprender los factores que llevan a la pÃ©rdida de clientes.

Tu desafÃ­o serÃ¡ recopilar, procesar y analizar los datos, utilizando Python y sus principales bibliotecas para extraer informaciÃ³n valiosa. A partir de tu anÃ¡lisis, el equipo de Data Science podrÃ¡ avanzar en modelos predictivos y desarrollar estrategias para reducir la evasiÃ³n.

Â¿QuÃ© vas a practicar?
âœ… Importar y manipular datos desde una API de manera eficiente.
âœ… Aplicar los conceptos de ETL (ExtracciÃ³n, TransformaciÃ³n y Carga) en la preparaciÃ³n de los datos.
âœ… Crear visualizaciones estratÃ©gicas para identificar patrones y tendencias.
âœ… Realizar un AnÃ¡lisis Exploratorio de Datos (EDA) y generar un informe con insights relevantes.

Â¡Ahora es tu turno! ğŸš€ Usa tus conocimientos para transformar datos en informaciÃ³n estratÃ©gica y ayudar a Telecom X a retener mÃ¡s clientes.

/

Crear el repositorio de tu proyecto en GitHub

DescripciÃ³n

A la hora de desarrollar proyectos, sabemos lo esencial que es organizar el trabajo desde el principio. Por lo tanto, en este desafÃ­o, tendrÃ¡s que crear un repositorio en GitHub para almacenar y versionar tu proyecto.

Incluso si aÃºn no has desarrollado ningÃºn cÃ³digo, el objetivo es crear una estructura inicial para el proyecto. A medida que avances, podrÃ¡s actualizar y agregar archivos al repositorio.

Materiales de apoyo
Si necesita ayuda, consulte los siguientes recursos:

Git - Acerca del Control de Versiones
Iniciando un repositorio con Git | Alura Cursos Online

Â¡Organizar tu proyecto desde el principio facilita el desarrollo y garantiza buenas prÃ¡cticas en el control de versiones! ğŸš€

& ya hice esto y ya estÃ¡ sincronizado git hub en vsc &
/

ğŸ“Œ ExtracciÃ³n(E - Extract)

/

ExtracciÃ³n de datos

DescripciÃ³n

Para iniciar tu anÃ¡lisis, necesitarÃ¡s importar los datos de la API de Telecom X. Estos datos estÃ¡n disponibles en formato JSON y contienen informaciÃ³n esencial sobre los clientes, incluyendo datos demogrÃ¡ficos, tipo de servicio contratado y estado de evasiÃ³n.

ğŸ“Œ Enlace de la API:
ğŸ”— challenge2-data-science-LATAM/TelecomX_Data.json at main Â· ingridcristh/challenge2-data-science-LATAM: https://github.com/ingridcristh/challenge2-data-science-LATAM/blob/main/TelecomX_Data.json

ğŸ”—GitHub - ingridcristh/challenge2-data-science-LATAM: https://github.com/ingridcristh/challenge2-data-science-LATAM

Â¿QuÃ© debes hacer?
âœ… Cargar los datos directamente desde la API utilizando Python.
âœ… Convertir los datos a un DataFrame de Pandas para facilitar su manipulaciÃ³n.

Este es el primer paso para transformar los datos en informaciÃ³n valiosa. Â¿Listo para programar? ğŸš€

& terminado &
/


ğŸ”§ TransformaciÃ³n (T - Transform)

/

Conoce el conjunto de datos

DescripciÃ³n

Ahora que has extraÃ­do los datos, es fundamental comprender la estructura del dataset y el significado de sus columnas. Esta etapa te ayudarÃ¡ a identificar quÃ© variables son mÃ¡s relevantes para el anÃ¡lisis de evasiÃ³n de clientes.

ğŸ“Œ Para facilitar este proceso, hemos creado un diccionario de datos con la descripciÃ³n de cada columna. Aunque no es obligatorio utilizarlo, puede ayudarte a comprender mejor la informaciÃ³n disponible.

ğŸ”— Enlace al diccionario y a la API

Â¿QuÃ© debes hacer?
âœ… Explorar las columnas del dataset y verificar sus tipos de datos.
âœ… Consultar el diccionario para comprender mejor el significado de las variables.
âœ… Identificar las columnas mÃ¡s relevantes para el anÃ¡lisis de evasiÃ³n.

ğŸ“Œ Tips:
ğŸ”— DocumentaciÃ³n de DataFrame.info()
ğŸ”— DocumentaciÃ³n de DataFrame.dtypes
& terminado &

/

ComprobaciÃ³n de incoherencias en los datos

DescripciÃ³n

En este paso, verifica si hay problemas en los datos que puedan afectar el anÃ¡lisis. Presta atenciÃ³n a valores ausentes, duplicados, errores de formato e inconsistencias en las categorÃ­as. Este proceso es esencial para asegurarte de que los datos estÃ©n listos para las siguientes etapas.

ğŸ“Œ Tips:

ğŸ”— DocumentaciÃ³n de pandas.unique()
ğŸ”— DocumentaciÃ³n de pandas.Series.dt.normalize()
& terminado &

/

Manejo de inconsistencias

DescripciÃ³n

Ahora que has identificado las inconsistencias, es momento de aplicar las correcciones necesarias. Ajusta los datos para asegurarte de que estÃ©n completos y coherentes, preparÃ¡ndolos para las siguientes etapas del anÃ¡lisis.

ğŸ“Œ Tips:

ğŸ”— ManipulaciÃ³n de strings en pandas: lower, replace, startswith y contains | Alura Cursos Online
& terminado &

/

Columna de cuentas diarias

DescripciÃ³n

Ahora que los datos estÃ¡n limpios, es momento de crear la columna "Cuentas_Diarias". Utiliza la facturaciÃ³n mensual para calcular el valor diario, proporcionando una visiÃ³n mÃ¡s detallada del comportamiento de los clientes a lo largo del tiempo.

ğŸ“Œ Esta columna te ayudarÃ¡ a profundizar en el anÃ¡lisis y a obtener informaciÃ³n valiosa para las siguientes etapas.
& terminado &

/

EstandarizaciÃ³n y transformaciÃ³n de datos (opcional)

DescripciÃ³n

La estandarizaciÃ³n y transformaciÃ³n de datos es una etapa opcional, pero altamente recomendada, ya que busca hacer que la informaciÃ³n sea mÃ¡s consistente, comprensible y adecuada para el anÃ¡lisis. Durante esta fase, por ejemplo, puedes convertir valores textuales como "SÃ­" y "No" en valores binarios (1 y 0), lo que facilita el procesamiento matemÃ¡tico y la aplicaciÃ³n de modelos analÃ­ticos.

AdemÃ¡s, traducir o renombrar columnas y datos hace que la informaciÃ³n sea mÃ¡s accesible y fÃ¡cil de entender, especialmente cuando se trabaja con fuentes externas o tÃ©rminos tÃ©cnicos. Aunque no es un paso obligatorio, puede mejorar significativamente la claridad y comunicaciÃ³n de los resultados, facilitando la interpretaciÃ³n y evitando confusiones, especialmente al compartir informaciÃ³n con stakeholders no tÃ©cnicos.
& terminado &

/

ğŸ“Š Carga y anÃ¡lisis(L - Load & Analysis)

/

AnÃ¡lisis Descriptivo

DescripciÃ³n

Para comenzar, realiza un anÃ¡lisis descriptivo de los datos, calculando mÃ©tricas como media, mediana, desviaciÃ³n estÃ¡ndar y otras medidas que ayuden a comprender mejor la distribuciÃ³n y el comportamiento de los clientes.

ğŸ“Œ Consejos:

ğŸ”— DocumentaciÃ³n de DataFrame.describe()
& terminado &

/

DistribuciÃ³n de evasiÃ³n

DescripciÃ³n

En este paso, el objetivo es comprender cÃ³mo estÃ¡ distribuida la variable "churn" (evasiÃ³n) entre los clientes. Utiliza grÃ¡ficos para visualizar la proporciÃ³n de clientes que permanecieron y los que se dieron de baja.
& terminado &

/

Recuento de evasiÃ³n por variables categÃ³ricas

DescripciÃ³n

Ahora, exploraremos cÃ³mo se distribuye la evasiÃ³n segÃºn variables categÃ³ricas, como gÃ©nero, tipo de contrato, mÃ©todo de pago, entre otras.

Este anÃ¡lisis puede revelar patrones interesantes, por ejemplo, si los clientes de ciertos perfiles tienen una mayor tendencia a cancelar el servicio, lo que ayudarÃ¡ a orientar acciones estratÃ©gicas.
& terminado &

/

Conteo de evasiÃ³n por variables numÃ©ricas

DescripciÃ³n

En este paso, explora cÃ³mo las variables numÃ©ricas, como "total gastado" o "tiempo de contrato", se distribuyen entre los clientes que cancelaron (evasiÃ³n) y los que no cancelaron.

Este anÃ¡lisis ayuda a entender si ciertos valores numÃ©ricos estÃ¡n mÃ¡s asociados con la evasiÃ³n, proporcionando insights sobre los factores que influyen en el comportamiento de los clientes.
& terminado &

/

Informe final

DescripciÃ³n

Finaliza el desafÃ­o elaborando un informe dentro del mismo notebook que resuma todo el trabajo realizado. El informe debe incluir:

ğŸ”¹ IntroducciÃ³n: Explica el objetivo del anÃ¡lisis y el problema de evasiÃ³n de clientes (Churn).

ğŸ”¹ Limpieza y Tratamiento de Datos: Describe los pasos realizados para importar, limpiar y procesar los datos.

ğŸ”¹ AnÃ¡lisis Exploratorio de Datos: Presenta los anÃ¡lisis realizados, incluyendo grÃ¡ficos y visualizaciones para identificar patrones.

ğŸ”¹ Conclusiones e Insights: Resume los principales hallazgos y cÃ³mo estos datos pueden ayudar a reducir la evasiÃ³n.

ğŸ”¹ Recomendaciones: Ofrece sugerencias estratÃ©gicas basadas en tu anÃ¡lisis.

AsegÃºrate de que el informe estÃ© bien estructurado, claro y respaldado por visualizaciones que refuercen tus conclusiones. ğŸš€

/

Â¡EXTRA!

/

Â¡Extra! AnÃ¡lisis de correlaciÃ³n entre variables

DescripciÃ³n

Esta actividad es un extra, por lo tanto es OPCIONAL.

Como un paso adicional, puedes explorar la correlaciÃ³n entre diferentes variables del dataset. Esto puede ayudar a identificar quÃ© factores tienen mayor relaciÃ³n con la evasiÃ³n de clientes, como:

ğŸ”¹ La relaciÃ³n entre la cuenta diaria y la evasiÃ³n.
ğŸ”¹ CÃ³mo la cantidad de servicios contratados afecta la probabilidad de churn.

Puedes usar la funciÃ³n corr() de Pandas para calcular las correlaciones y visualizar los resultados con grÃ¡ficos de dispersiÃ³n o matrices de correlaciÃ³n.

Este anÃ¡lisis adicional puede proporcionar insights valiosos para la creaciÃ³n de modelos predictivos mÃ¡s robustos. ğŸš€

/

Â¡Entrega del Desafio!

/

ğŸ“– README ğŸ“–

DescripciÃ³n

El README es un elemento clave en cualquier proyecto de desarrollo, ya que proporciona una descripciÃ³n clara y detallada del propÃ³sito, la estructura y el uso del cÃ³digo.

Cuando participas en un proceso de selecciÃ³n, el README es imprescindible para comunicar cÃ³mo utilizar el proyecto.

Este archivo, con la extensiÃ³n .md (Markdown), es el punto de referencia inicial para cualquiera que quiera entender y trabajar con su cÃ³digo.

Un buen README incluye informaciÃ³n sobre la instalaciÃ³n, dependencias, cÃ³mo ejecutar el proyecto y posibles problemas o soluciones.

Un README bien estructurado facilita que otros desarrolladores comprendan el proyecto.

AquÃ­ hay un artÃ­culo con los pasos para crear un README increÃ­ble:

/

Entrega del desafÃ­o

Etiquetas
Git/GitHub
Entrega del Proyecto

DescripciÃ³n

Para enviar formalmente su desafÃ­o, debe seguir los pasos que se enumeran en la lista de verificaciÃ³n a continuaciÃ³n.

Checklist
Eliminar
0%
Sube el proyecto y el README a GitHub

Realizar la entrega a travÃ©s del curso â€œ__â€

Publica tu proyecto y/o un vÃ­deo en Linkedin